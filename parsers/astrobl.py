import requests
from bs4 import BeautifulSoup
from datetime import datetime, timedelta
import time
import os
import re
import yaml
import shutil
from docx import Document
from docx.shared import Inches
from docx.enum.table import WD_ALIGN_VERTICAL


class AstroblParser:
    def __init__(self):
        self.base_url = "https://www.astrobl.ru"
        self.list_url = f"{self.base_url}/press/news"
        self.headers = {
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/122.0 Safari/537.36'
        }
        self.months_ru = {
            '—è–Ω–≤–∞—Ä—è': 1, '—Ñ–µ–≤—Ä–∞–ª—è': 2, '–º–∞—Ä—Ç–∞': 3, '–∞–ø—Ä–µ–ª—è': 4,
            '–º–∞—è': 5, '–∏—é–Ω—è': 6, '–∏—é–ª—è': 7, '–∞–≤–≥—É—Å—Ç–∞': 8,
            '—Å–µ–Ω—Ç—è–±—Ä—è': 9, '–æ–∫—Ç—è–±—Ä—è': 10, '–Ω–æ—è–±—Ä—è': 11, '–¥–µ–∫–∞–±—Ä—è': 12
        }
        self.start_date, self.end_date, self.search_list, self.reports_path, self.config = self.load_date_config()

    def load_date_config(self):
        try:
            config_paths = [
                "parsers/config.yaml",
                "config.yaml",
                os.path.join(os.path.dirname(__file__), "config.yaml")
            ]
            config_path = None
            for path in config_paths:
                if os.path.exists(path):
                    config_path = path
                    break
            if config_path:
                with open(config_path, 'r', encoding='utf-8') as f:
                    config = yaml.safe_load(f)
                reports = config.get('reports', {})
                return (
                    reports.get('start_date'),
                    reports.get('end_date'),
                    reports.get('search_list', []),
                    reports.get('path', '../reports/'),
                    config,
                )
            return "2025-09-01", "2025-09-23", [], "../reports/", {}
        except Exception:
            return "2025-09-01", "2025-09-23", [], "../reports/", {}

    def format_period_ru(self, start_iso: str, end_iso: str) -> str:
        try:
            start_dt = datetime.strptime(start_iso, "%Y-%m-%d")
            end_dt = datetime.strptime(end_iso, "%Y-%m-%d")
        except Exception:
            return f"{start_iso} ‚Äî {end_iso}"
        months_gen = [
            "—è–Ω–≤–∞—Ä—è", "—Ñ–µ–≤—Ä–∞–ª—è", "–º–∞—Ä—Ç–∞", "–∞–ø—Ä–µ–ª—è", "–º–∞—è", "–∏—é–Ω—è",
            "–∏—é–ª—è", "–∞–≤–≥—É—Å—Ç–∞", "—Å–µ–Ω—Ç—è–±—Ä—è", "–æ–∫—Ç—è–±—Ä—è", "–Ω–æ—è–±—Ä—è", "–¥–µ–∫–∞–±—Ä—è"
        ]
        if start_dt.year == end_dt.year:
            if start_dt.month == end_dt.month:
                month_name = months_gen[end_dt.month - 1]
                return f"{start_dt.day} –ø–æ {end_dt.day} {month_name} {end_dt.year}"
            else:
                return f"{start_dt.day} {months_gen[start_dt.month-1]} –ø–æ {end_dt.day} {months_gen[end_dt.month-1]} {end_dt.year}"
        else:
            return f"{start_dt.day} {months_gen[start_dt.month-1]} {start_dt.year} –ø–æ {end_dt.day} {months_gen[end_dt.month-1]} {end_dt.year}"

    def check_keywords_in_title(self, title: str):
        if not self.search_list or not title:
            return False, []
        found = []
        for kw in self.search_list:
            if re.search(re.escape(kw), title, flags=re.IGNORECASE):
                found.append(kw)
        return len(found) > 0, found

    def get(self, url: str):
        try:
            resp = requests.get(url, headers=self.headers, timeout=15)
            resp.raise_for_status()
            return resp.text
        except Exception as e:
            print(f"–û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ {url}: {e}")
            return None

    def build_period_param(self) -> str:
        # DD.MM.YYYY+-+DD.MM.YYYY
        try:
            sd = datetime.strptime(self.start_date, "%Y-%m-%d").strftime("%d.%m.%Y")
            ed = datetime.strptime(self.end_date, "%Y-%m-%d").strftime("%d.%m.%Y")
        except Exception:
            ed = datetime.now().strftime("%d.%m.%Y")
            sd = (datetime.now() - timedelta(days=3)).strftime("%d.%m.%Y")
        return f"{sd}+-+{ed}"

    def parse_date_text(self, text: str) -> str:
        # –ü—Ä–∏–º–µ—Ä—ã: "–°–µ–≥–æ–¥–Ω—è –≤ 13:13", "–í—á–µ—Ä–∞ –≤ 9:28", "23 —Å–µ–Ω—Ç—è–±—Ä—è 2025, 14:55"
        t = text.strip()
        today = datetime.now()
        if t.lower().startswith("—Å–µ–≥–æ–¥–Ω—è"):
            return today.strftime("%Y-%m-%d")
        if t.lower().startswith("–≤—á–µ—Ä–∞"):
            return (today - timedelta(days=1)).strftime("%Y-%m-%d")
        m = re.search(r"(\d{1,2})\s+(\w+)\s+(\d{4})", t)
        if m:
            day = int(m.group(1))
            month_name = m.group(2).lower()
            year = int(m.group(3))
            month = self.months_ru.get(month_name)
            if month:
                try:
                    return datetime(year, month, day).strftime("%Y-%m-%d")
                except Exception:
                    return t
        return t

    def parse_list_page(self, html: str):
        soup = BeautifulSoup(html, 'html.parser')
        articles = soup.find_all('article', class_='news')
        items = []
        for art in articles:
            try:
                a = art.find('a')
                if not a:
                    continue
                title_el = art.select_one('.title h5')
                title = title_el.get_text(strip=True) if title_el else a.get('title') or ''
                href = a.get('href') or ''
                url = href if href.startswith('http') else (self.base_url + href)
                img_div = art.select_one('.img')
                image_url = ''
                if img_div and img_div.has_attr('style'):
                    style = img_div['style']
                    m = re.search(r"url\(\"?([^\)\"]+)\"?\)", style)
                    if m:
                        src = m.group(1)
                        image_url = src if src.startswith('http') else (self.base_url + src)
                date_span = art.select_one('.date span[title="–î–∞—Ç–∞ –ø—É–±–ª–∏–∫–∞—Ü–∏–∏"]') or art.select_one('.date span')
                date_text = date_span.get_text(strip=True) if date_span else ''
                parsed_date = self.parse_date_text(date_text)
                has_kw, found_kw = self.check_keywords_in_title(title)
                items.append({
                    'title': title,
                    'url': url,
                    'date': parsed_date,
                    'date_original': date_text,
                    'author': '',
                    'image_url': image_url,
                    'has_search_keywords': has_kw,
                    'found_keywords': found_kw,
                    'parsed_at': datetime.now().isoformat(),
                })
            except Exception as e:
                print(f"–û—à–∏–±–∫–∞ —Å—Ç–∞—Ç—å–∏: {e}")
                continue
        return items

    def create_news_table(self, doc, news_with_keywords, company_config):
        if not news_with_keywords:
            return None
        site_domain = company_config.get('domain', 'astrobl.ru')
        logo_path = company_config.get('logo_path', '../static/logos/logo_juka.png')
        table = doc.add_table(rows=1, cols=4)
        table.style = 'Table Grid'
        headers = [
            '–ù–∞–∏–º–µ–Ω–æ–≤–∞–Ω–∏–µ —Ä–∞–¥–∏–æ—Å—Ç–∞–Ω—Ü–∏–∏/—Å–∞–π—Ç–∞',
            '–î–∞—Ç–∞ –∏ –≤—Ä–µ–º—è –≤—ã—Ö–æ–¥–∞ –≤ —ç—Ñ–∏—Ä',
            '–ù–∞–∑–≤–∞–Ω–∏–µ –ø—Ä–æ–≥—Ä–∞–º–º—ã',
            '–ù–∞–∑–≤–∞–Ω–∏–µ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–æ–Ω–Ω–æ–≥–æ –º–∞—Ç–µ—Ä–∏–∞–ª–∞/ —Å—Å—ã–ª–∫–∞ –Ω–∞ –ø—É–±–ª–∏–∫–∞—Ü–∏—é',
        ]
        for i, txt in enumerate(headers):
            cell = table.rows[0].cells[i]
            cell.text = txt
            cell.vertical_alignment = WD_ALIGN_VERTICAL.CENTER
            for p in cell.paragraphs:
                for r in p.runs:
                    r.font.bold = True
                if i < 3:
                    p.alignment = 1
        for news in news_with_keywords:
            formatted_date = ''
            if news.get('date') and re.match(r"\d{4}-\d{2}-\d{2}", news['date']):
                try:
                    d = datetime.strptime(news['date'], '%Y-%m-%d')
                    formatted_date = d.strftime('%d.%m.%y')
                except Exception:
                    formatted_date = news['date']
            else:
                formatted_date = ''
            r1 = table.add_row().cells
            for c in r1:
                c.vertical_alignment = WD_ALIGN_VERTICAL.CENTER
            try:
                if os.path.exists(logo_path):
                    p = r1[0].paragraphs[0]
                    p.alignment = 1
                    run = p.runs[0] if p.runs else p.add_run()
                    run.add_picture(logo_path, width=Inches(0.5))
                else:
                    r1[0].text = '[–õ–û–ì–û]'
                    r1[0].paragraphs[0].alignment = 1
            except Exception:
                r1[0].text = '[–õ–û–ì–û]'
                r1[0].paragraphs[0].alignment = 1
            r1[1].text = formatted_date
            r1[1].paragraphs[0].alignment = 1
            r1[2].text = '¬´–ù–æ–≤–æ—Å—Ç–∏¬ª'
            r1[2].paragraphs[0].alignment = 1
            r1[3].text = news['title']
            r2 = table.add_row().cells
            for c in r2:
                c.vertical_alignment = WD_ALIGN_VERTICAL.CENTER
            r2[0].text = site_domain
            r2[0].paragraphs[0].alignment = 1
            r2[1].text = formatted_date
            r2[1].paragraphs[0].alignment = 1
            r2[2].text = '¬´–ù–æ–≤–æ—Å—Ç–∏¬ª'
            r2[2].paragraphs[0].alignment = 1
            r2[3].text = news.get('url', '')
        return table

    def replace_variables_in_paragraph(self, paragraph, company_config, news_with_keywords, doc):
        period_text = self.format_period_ru(self.start_date, self.end_date)
        n_value = str((len(news_with_keywords) if news_with_keywords else 0) * 10)
        replacements = {
            '$pre_company_full': company_config.get('pre_company_full', ''),
            '$company_short': company_config.get('company_short', ''),
            '$post_company_full': company_config.get('post_company_full', ''),
            '$date': period_text,
            '$legal_address': company_config.get('legal_address', ''),
            '$inn_kpp': company_config.get('inn_kpp', ''),
            '$email': company_config.get('email', ''),
            '$ceo_name': company_config.get('ceo_name', ''),
            '$n': n_value,
        }
        text = paragraph.text
        if '$report' in text:
            parts = text.split('$report')
            before = parts[0]
            after = parts[1] if len(parts) > 1 else ''
            for k, v in replacements.items():
                before = before.replace(k, v)
                after = after.replace(k, v)
            for r in paragraph.runs:
                r.text = ''
            if paragraph.runs:
                paragraph.runs[0].text = before
            else:
                paragraph.add_run(before)
            pe = paragraph._element
            parent = pe.getparent()
            idx = list(parent).index(pe)
            table = self.create_news_table(doc, news_with_keywords, company_config or {})
            if table is not None:
                parent.insert(idx + 1, table._element)
            if after.strip():
                new_p = doc.add_paragraph(after)
                parent.insert(idx + 2, new_p._element)
            return True
        new_text = text
        changed = False
        for k, v in replacements.items():
            if k in new_text:
                new_text = new_text.replace(k, v)
                changed = True
        if changed:
            for r in paragraph.runs:
                r.text = ''
            if paragraph.runs:
                paragraph.runs[0].text = new_text
            else:
                paragraph.add_run(new_text)
        return changed

    def replace_variables_in_cell(self, cell, company_config, news_with_keywords, doc):
        for p in cell.paragraphs:
            self.replace_variables_in_paragraph(p, company_config, news_with_keywords, doc)

    def process_template_document(self, news_with_keywords, company_name='–Æ–º–æ—Ä'):
        try:
            company_config = self.config.get('reports', {}).get('docs', {}).get(company_name, {})
            template_paths = [
                "static/template.docx",
                "../static/template.docx",
            ]
            template_path = None
            for path in template_paths:
                if os.path.exists(path):
                    template_path = path
                    break
            if not template_path:
                print("‚ùå template.docx –Ω–µ –Ω–∞–π–¥–µ–Ω")
                return None
            os.makedirs(self.reports_path, exist_ok=True)
            out_name = f"processed_document_{company_name}_{datetime.now().strftime('%Y%m%d_%H%M%S')}.docx"
            out_path = os.path.join(self.reports_path, out_name)
            shutil.copy2(template_path, out_path)
            doc = Document(out_path)
            paragraphs = list(doc.paragraphs)
            for p in paragraphs:
                if p.text.strip():
                    self.replace_variables_in_paragraph(p, company_config, news_with_keywords, doc)
            for table in doc.tables:
                for row in table.rows:
                    for cell in row.cells:
                        if cell.text.strip():
                            self.replace_variables_in_cell(cell, company_config, news_with_keywords, doc)
            doc.save(out_path)
            print(f"‚úÖ –î–æ–∫—É–º–µ–Ω—Ç —Å–æ—Ö—Ä–∞–Ω–µ–Ω: {out_path}")
            return out_path
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –¥–æ–∫—É–º–µ–Ω—Ç–∞: {e}")
            return None

    def run(self):
        print("–ó–∞–ø—É—Å–∫ –ø–∞—Ä—Å–∏–Ω–≥–∞ astrobl.ru...")
        print(f"–ü–µ—Ä–∏–æ–¥: {self.start_date} ‚Äî {self.end_date}")
        period_param = self.build_period_param()
        page = 0
        all_items = []
        seen = set()
        while True:
            url = f"{self.list_url}?page={page}&period={period_param}"
            print(f"–°—Ç—Ä–∞–Ω–∏—Ü–∞ {page}: {url}")
            html = self.get(url)
            if not html:
                print("‚ùå –ù–µ—Ç HTML, –ø—Ä–µ—Ä—ã–≤–∞–µ–º")
                break
            items = self.parse_list_page(html)
            if not items:
                print("üèÅ –ö–æ–Ω—Ç–µ–Ω—Ç –∑–∞–∫–æ–Ω—á–∏–ª—Å—è, –≤—ã—Ö–æ–¥–∏–º")
                break
            new_cnt = 0
            for it in items:
                key = (it['title'], it['url'])
                if key not in seen:
                    seen.add(key)
                    all_items.append(it)
                    new_cnt += 1
            print(f"–î–æ–±–∞–≤–ª–µ–Ω–æ —É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö: {new_cnt}")
            page += 1
            time.sleep(0.8)
            if page > 100:
                print("‚ö†Ô∏è –õ–∏–º–∏—Ç —Å—Ç—Ä–∞–Ω–∏—Ü 100")
                break
        print(f"–ò—Ç–æ–≥–æ —Å–æ–±—Ä–∞–Ω–æ: {len(all_items)}")
        news_with_kw = [x for x in all_items if x.get('has_search_keywords')]
        print(f"–°–æ–≤–ø–∞–¥–µ–Ω–∏–π –ø–æ –∫–ª—é—á–µ–≤—ã–º —Å–ª–æ–≤–∞–º: {len(news_with_kw)}")
        self.process_template_document(news_with_kw, company_name='–ê—Å—Ç—Ä–æ–±–æ–ª')


def main():
    AstroblParser().run()


if __name__ == "__main__":
    main()