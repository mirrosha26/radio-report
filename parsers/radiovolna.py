import requests
from bs4 import BeautifulSoup
import json
from datetime import datetime
import time
import os
import re
import yaml
import shutil
from docx import Document
from docx.shared import Inches
from docx.enum.table import WD_ALIGN_VERTICAL  # –î–æ–±–∞–≤–ª—è–µ–º –∏–º–ø–æ—Ä—Ç –¥–ª—è –≤–µ—Ä—Ç–∏–∫–∞–ª—å–Ω–æ–≥–æ –≤—ã—Ä–∞–≤–Ω–∏–≤–∞–Ω–∏—è
from docx.oxml.shared import OxmlElement, qn


class RadioVolnaParser:
    def __init__(self):
        self.base_url = "https://radiovolna.fm"
        self.headers = {
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'
        }
        self.session = requests.Session()
        self.session.headers.update(self.headers)
        
        # –°–ª–æ–≤–∞—Ä—å –¥–ª—è –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏—è —Ä—É—Å—Å–∫–∏—Ö –º–µ—Å—è—Ü–µ–≤
        self.months_ru = {
            '—è–Ω–≤–∞—Ä—è': 1, '—Ñ–µ–≤—Ä–∞–ª—è': 2, '–º–∞—Ä—Ç–∞': 3, '–∞–ø—Ä–µ–ª—è': 4,
            '–º–∞—è': 5, '–∏—é–Ω—è': 6, '–∏—é–ª—è': 7, '–∞–≤–≥—É—Å—Ç–∞': 8,
            '—Å–µ–Ω—Ç—è–±—Ä—è': 9, '–æ–∫—Ç—è–±—Ä—è': 10, '–Ω–æ—è–±—Ä—è': 11, '–¥–µ–∫–∞–±—Ä—è': 12
        }
        
        # –ó–∞–≥—Ä—É–∂–∞–µ–º –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é –¥–∞—Ç –∏ –ø–æ–∏—Å–∫–æ–≤—ã—Ö —Å–ª–æ–≤
        self.start_date, self.end_date, self.search_list, self.reports_path, self.config = self.load_date_config()

    def load_date_config(self):
        """–ó–∞–≥—Ä—É–∂–∞–µ—Ç –¥–∏–∞–ø–∞–∑–æ–Ω –¥–∞—Ç –∏ —Å–ø–∏—Å–æ–∫ –ø–æ–∏—Å–∫–æ–≤—ã—Ö —Å–ª–æ–≤ –∏–∑ config.yaml"""
        try:
            # –ü—Ä–æ–±—É–µ–º —Ä–∞–∑–Ω—ã–µ –≤–∞—Ä–∏–∞–Ω—Ç—ã –ø—É—Ç–∏ –∫ –∫–æ–Ω—Ñ–∏–≥—É
            config_paths = [
                "parsers/config.yaml",
                "config.yaml", 
                os.path.join(os.path.dirname(__file__), "config.yaml")
            ]
            
            config_path = None
            for path in config_paths:
                if os.path.exists(path):
                    config_path = path
                    break
            
            if config_path:
                with open(config_path, 'r', encoding='utf-8') as f:
                    config = yaml.safe_load(f)
                    
                reports_section = config.get('reports', {})
                start_date = reports_section.get('start_date')
                end_date = reports_section.get('end_date')
                search_list = reports_section.get('search_list', [])
                reports_path = reports_section.get('path', 'data')
                
                if start_date and end_date:
                    print(f"üìÖ –î–∏–∞–ø–∞–∑–æ–Ω –¥–∞—Ç –∏–∑ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏: {start_date} ‚Äî {end_date}")
                    print(f"üîç –ü–æ–∏—Å–∫–æ–≤—ã–µ —Å–ª–æ–≤–∞: {search_list}")
                    return start_date, end_date, search_list, reports_path, config
        
            # –ó–Ω–∞—á–µ–Ω–∏—è –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é, –µ—Å–ª–∏ –∫–æ–Ω—Ñ–∏–≥ –Ω–µ –Ω–∞–π–¥–µ–Ω
            print("‚ö†Ô∏è –ö–æ–Ω—Ñ–∏–≥ –Ω–µ –Ω–∞–π–¥–µ–Ω, –∏—Å–ø–æ–ª—å–∑—É—é—Ç—Å—è –∑–Ω–∞—á–µ–Ω–∏—è –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é")
            return "2025-09-01", "2025-09-23", [], "data", {}
            
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –∫–æ–Ω—Ñ–∏–≥–∞: {e}")
            return "2025-09-01", "2025-09-23", [], "data", {}

    def check_keywords_in_title(self, title):
        """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç –Ω–∞–ª–∏—á–∏–µ –∫–ª—é—á–µ–≤—ã—Ö —Å–ª–æ–≤ –≤ –∑–∞–≥–æ–ª–æ–≤–∫–µ —Å –ø–æ–º–æ—â—å—é —Ä–µ–≥—É–ª—è—Ä–Ω—ã—Ö –≤—ã—Ä–∞–∂–µ–Ω–∏–π"""
        if not self.search_list or not title:
            return False, []
        
        found_keywords = []
        
        for keyword in self.search_list:
            # –°–æ–∑–¥–∞–µ–º —Ä–µ–≥—É–ª—è—Ä–Ω–æ–µ –≤—ã—Ä–∞–∂–µ–Ω–∏–µ –¥–ª—è –ø–æ–∏—Å–∫–∞ —Å–ª–æ–≤–∞ (–∏–≥–Ω–æ—Ä–∏—Ä—É–µ–º —Ä–µ–≥–∏—Å—Ç—Ä)
            pattern = re.compile(re.escape(keyword), re.IGNORECASE)
            if pattern.search(title):
                found_keywords.append(keyword)
        
        return len(found_keywords) > 0, found_keywords

    def is_date_in_range(self, date_str):
        """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç, –ø–æ–ø–∞–¥–∞–µ—Ç –ª–∏ –¥–∞—Ç–∞ –≤ –∑–∞–¥–∞–Ω–Ω—ã–π –¥–∏–∞–ø–∞–∑–æ–Ω"""
        if not date_str or date_str == "":
            return True  # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º –Ω–æ–≤–æ—Å—Ç–∏ –±–µ–∑ –¥–∞—Ç—ã
        
        try:
            # –ï—Å–ª–∏ –¥–∞—Ç–∞ —É–∂–µ –≤ —Ñ–æ—Ä–º–∞—Ç–µ YYYY-MM-DD
            if re.match(r'\d{4}-\d{2}-\d{2}', date_str):
                return self.start_date <= date_str <= self.end_date
            return True
        except:
            return True  # –í —Å–ª—É—á–∞–µ –æ—à–∏–±–∫–∏ –ø—Ä–æ–ø—É—Å–∫–∞–µ–º

    def parse_russian_date(self, date_str):
        """–ü—Ä–µ–æ–±—Ä–∞–∑—É–µ—Ç —Ä—É—Å—Å–∫—É—é –¥–∞—Ç—É –≤ —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç ISO"""
        if not date_str:
            return None
        
        try:
            # –ò—â–µ–º –ø–∞—Ç—Ç–µ—Ä–Ω: —á–∏—Å–ª–æ + –º–µ—Å—è—Ü + –≥–æ–¥
            pattern = r'(\d{1,2})\s+(\w+)\s+(\d{4})'
            match = re.search(pattern, date_str)
            
            if match:
                day = int(match.group(1))
                month_name = match.group(2)
                year = int(match.group(3))
                
                # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º –Ω–∞–∑–≤–∞–Ω–∏–µ –º–µ—Å—è—Ü–∞ –≤ –Ω–æ–º–µ—Ä
                if month_name in self.months_ru:
                    month = self.months_ru[month_name]
                    # –°–æ–∑–¥–∞–µ–º –æ–±—ä–µ–∫—Ç datetime –∏ –≤–æ–∑–≤—Ä–∞—â–∞–µ–º –≤ —Ñ–æ—Ä–º–∞—Ç–µ ISO
                    date_obj = datetime(year, month, day)
                    return date_obj.strftime('%Y-%m-%d')
            
            return date_str  # –í–æ–∑–≤—Ä–∞—â–∞–µ–º –æ—Ä–∏–≥–∏–Ω–∞–ª, –µ—Å–ª–∏ –Ω–µ —É–¥–∞–ª–æ—Å—å —Ä–∞—Å–ø–∞—Ä—Å–∏—Ç—å
            
        except Exception as e:
            print(f"–û—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞ –¥–∞—Ç—ã '{date_str}': {e}")
            return date_str

    def get_page_content(self, url):
        """–ü–æ–ª—É—á–∞–µ—Ç —Å–æ–¥–µ—Ä–∂–∏–º–æ–µ —Å—Ç—Ä–∞–Ω–∏—Ü—ã"""
        try:
            response = self.session.get(url, timeout=10)
            response.raise_for_status()
            return response.text
        except requests.RequestException as e:
            print(f"–û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ {url}: {e}")
            return None

    def parse_new_materials_section(self, page_content):
        """–ü–∞—Ä—Å–∏—Ç —Ç–æ–ª—å–∫–æ —Å–µ–∫—Ü–∏—é '–ù–æ–≤—ã–µ –º–∞—Ç–µ—Ä–∏–∞–ª—ã'"""
        soup = BeautifulSoup(page_content, 'html.parser')
        news_items = []

        # –ò—â–µ–º —Å–µ–∫—Ü–∏—é —Å –∑–∞–≥–æ–ª–æ–≤–∫–æ–º "–ù–æ–≤—ã–µ –º–∞—Ç–µ—Ä–∏–∞–ª—ã"
        sections = soup.find_all('section', class_='l-section')
        
        target_section = None
        for section in sections:
            title_elem = section.find('h2', class_='l-section__title')
            if title_elem and '–ù–æ–≤—ã–µ –º–∞—Ç–µ—Ä–∏–∞–ª—ã' in title_elem.get_text():
                target_section = section
                break
        
        if not target_section:
            print("–°–µ–∫—Ü–∏—è '–ù–æ–≤—ã–µ –º–∞—Ç–µ—Ä–∏–∞–ª—ã' –Ω–µ –Ω–∞–π–¥–µ–Ω–∞")
            return news_items

        print("–ù–∞–π–¥–µ–Ω–∞ —Å–µ–∫—Ü–∏—è '–ù–æ–≤—ã–µ –º–∞—Ç–µ—Ä–∏–∞–ª—ã'")
        
        # –ò—â–µ–º –≤—Å–µ –Ω–æ–≤–æ—Å—Ç–Ω—ã–µ –±–ª–æ–∫–∏ –≤ —ç—Ç–æ–π —Å–µ–∫—Ü–∏–∏
        news_blocks = target_section.find_all('div', class_='b-section-item')
        print(f"–ù–∞–π–¥–µ–Ω–æ {len(news_blocks)} –Ω–æ–≤–æ—Å—Ç–Ω—ã—Ö –±–ª–æ–∫–æ–≤")
        
        for i, news_block in enumerate(news_blocks, 1):
            try:
                # –ò–∑–≤–ª–µ–∫–∞–µ–º –∑–∞–≥–æ–ª–æ–≤–æ–∫
                title_elem = news_block.find('h3', class_='b-section-item__title')
                if not title_elem:
                    continue
                
                title_link = title_elem.find('a')
                if not title_link:
                    continue
                
                title = title_link.get_text(strip=True)
                href = title_link.get('href')
                
                # –§–æ—Ä–º–∏—Ä—É–µ–º –ø–æ–ª–Ω—ã–π URL
                if href.startswith('/'):
                    full_url = self.base_url + href
                else:
                    full_url = href
                
                # –ò–∑–≤–ª–µ–∫–∞–µ–º –¥–∞—Ç—É
                date_text = ""
                meta_items = news_block.find_all('div', class_='b-meta-item')
                for meta_item in meta_items:
                    span = meta_item.find('span', class_='fa-clock-o')
                    if span:
                        date_span = span.find_next_sibling('span')
                        if date_span:
                            date_text = date_span.get_text(strip=True)
                        break
                
                # –ò–∑–≤–ª–µ–∫–∞–µ–º –∞–≤—Ç–æ—Ä–∞
                author = ""
                for meta_item in meta_items:
                    user_span = meta_item.find('span', class_='fa-user')
                    if user_span:
                        # –ü–æ–ª—É—á–∞–µ–º —Ç–µ–∫—Å—Ç –ø–æ—Å–ª–µ –∏–∫–æ–Ω–∫–∏ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
                        author_text = meta_item.get_text(strip=True)
                        author = author_text.strip()
                        break
                
                # –ò–∑–≤–ª–µ–∫–∞–µ–º URL –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
                image_url = ""
                picture_div = news_block.find('div', class_='b-section-item__picture')
                if picture_div:
                    img = picture_div.find('img')
                    if img:
                        img_src = img.get('src') or img.get('data-src')
                        if img_src:
                            if img_src.startswith('/'):
                                image_url = self.base_url + img_src
                            else:
                                image_url = img_src
                
                # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º –¥–∞—Ç—É
                parsed_date = self.parse_russian_date(date_text)
                
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –ø–æ–ø–∞–¥–∞–µ—Ç –ª–∏ –¥–∞—Ç–∞ –≤ –¥–∏–∞–ø–∞–∑–æ–Ω
                if not self.is_date_in_range(parsed_date):
                    continue
                
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ –∫–ª—é—á–µ–≤—ã—Ö —Å–ª–æ–≤ –≤ –∑–∞–≥–æ–ª–æ–≤–∫–µ
                has_keywords, found_keywords = self.check_keywords_in_title(title)
                
                news_item = {
                    'title': title,
                    'url': full_url,
                    'date': parsed_date,
                    'date_original': date_text,  # –°–æ—Ö—Ä–∞–Ω—è–µ–º –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—É—é –¥–∞—Ç—É
                    'author': author,
                    'image_url': image_url,
                    'has_search_keywords': has_keywords,
                    'found_keywords': found_keywords,
                    'parsed_at': datetime.now().isoformat()
                }
                
                news_items.append(news_item)
                if has_keywords:
                    print(f"‚úì –ë–ª–æ–∫ {i}: {title} üîç [{', '.join(found_keywords)}]")
                else:
                    print(f"‚úì –ë–ª–æ–∫ {i}: {title}")
                
            except Exception as e:
                print(f"‚úó –û—à–∏–±–∫–∞ –≤ –±–ª–æ–∫–µ {i}: {e}")
                continue
        
        return news_items

    def save_to_json(self, data, filename):
        """–°–æ—Ö—Ä–∞–Ω—è–µ—Ç –¥–∞–Ω–Ω—ã–µ –≤ JSON —Ñ–∞–π–ª –≤ –ø–∞–ø–∫—É reports"""
        try:
            # –°–æ–∑–¥–∞–µ–º –ø–∞–ø–∫—É reports, –µ—Å–ª–∏ –µ—ë –Ω–µ—Ç
            os.makedirs(self.reports_path, exist_ok=True)
            
            # –ü–æ–ª–Ω—ã–π –ø—É—Ç—å –∫ —Ñ–∞–π–ª—É
            filepath = os.path.join(self.reports_path, filename)
            
            with open(filepath, 'w', encoding='utf-8') as f:
                json.dump(data, f, ensure_ascii=False, indent=2)
            print(f"–î–∞–Ω–Ω—ã–µ —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤ {filepath}")
            return filepath
        except Exception as e:
            print(f"–û—à–∏–±–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è: {e}")
            return None

    def create_news_table(self, doc, news_with_keywords, company_config):
        """–°–æ–∑–¥–∞–µ—Ç —Ç–∞–±–ª–∏—Ü—É —Å –Ω–æ–≤–æ—Å—Ç—è–º–∏"""
        if not news_with_keywords:
            return None
        
        # –ü–æ–ª—É—á–∞–µ–º –¥–æ–º–µ–Ω –∏ –ø—É—Ç—å –∫ –ª–æ–≥–æ –∏–∑ –∫–æ–Ω—Ñ–∏–≥–∞
        site_domain = company_config.get('domain', 'radiovolna.fm')
        logo_path = company_config.get('logo_path', '../static/logos/logo_juka.png')
        
        # –°–æ–∑–¥–∞–µ–º —Ç–∞–±–ª–∏—Ü—É
        # –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å—Ç—Ä–æ–∫: 1 (–∑–∞–≥–æ–ª–æ–≤–æ–∫) + (–∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –Ω–æ–≤–æ—Å—Ç–µ–π * 2)
        table = doc.add_table(rows=1, cols=4)
        table.style = 'Table Grid'  # –°—Ç–∏–ª—å —Ç–∞–±–ª–∏—Ü—ã —Å –≥—Ä–∞–Ω–∏—Ü–∞–º–∏
        
        # –ó–∞–≥–æ–ª–æ–≤–∫–∏ —Å—Ç–æ–ª–±—Ü–æ–≤
        header_cells = table.rows[0].cells
        header_cells[0].text = '–ù–∞–∏–º–µ–Ω–æ–≤–∞–Ω–∏–µ —Ä–∞–¥–∏–æ—Å—Ç–∞–Ω—Ü–∏–∏/—Å–∞–π—Ç–∞'
        header_cells[1].text = '–î–∞—Ç–∞ –∏ –≤—Ä–µ–º—è –≤—ã—Ö–æ–¥–∞ –≤ —ç—Ñ–∏—Ä'
        header_cells[2].text = '–ù–∞–∑–≤–∞–Ω–∏–µ –ø—Ä–æ–≥—Ä–∞–º–º—ã'
        header_cells[3].text = '–ù–∞–∑–≤–∞–Ω–∏–µ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–æ–Ω–Ω–æ–≥–æ –º–∞—Ç–µ—Ä–∏–∞–ª–∞/ —Å—Å—ã–ª–∫–∞ –Ω–∞ –ø—É–±–ª–∏–∫–∞—Ü–∏—é'
        
        # –î–µ–ª–∞–µ–º –∑–∞–≥–æ–ª–æ–≤–∫–∏ –∂–∏—Ä–Ω—ã–º–∏, —Ü–µ–Ω—Ç—Ä–∏—Ä—É–µ–º –ø–µ—Ä–≤—ã–µ 3 —Å—Ç–æ–ª–±—Ü–∞ –∏ –≤—ã—Ä–∞–≤–Ω–∏–≤–∞–µ–º –ø–æ –≤–µ—Ä—Ç–∏–∫–∞–ª–∏
        for i, cell in enumerate(header_cells):
            # –í–µ—Ä—Ç–∏–∫–∞–ª—å–Ω–æ–µ —Ü–µ–Ω—Ç—Ä–∏—Ä–æ–≤–∞–Ω–∏–µ –¥–ª—è –≤—Å–µ—Ö —è—á–µ–µ–∫ –∑–∞–≥–æ–ª–æ–≤–∫–∞
            cell.vertical_alignment = WD_ALIGN_VERTICAL.CENTER
            
            for paragraph in cell.paragraphs:
                for run in paragraph.runs:
                    run.font.bold = True
                # –¶–µ–Ω—Ç—Ä–∏—Ä—É–µ–º –ø–µ—Ä–≤—ã–µ 3 —Å—Ç–æ–ª–±—Ü–∞ –≥–æ—Ä–∏–∑–æ–Ω—Ç–∞–ª—å–Ω–æ
                if i < 3:
                    paragraph.alignment = 1  # 1 = —Ü–µ–Ω—Ç—Ä–∏—Ä–æ–≤–∞–Ω–∏–µ
        
        # –î–æ–±–∞–≤–ª—è–µ–º —Å—Ç—Ä–æ–∫–∏ —Å –Ω–æ–≤–æ—Å—Ç—è–º–∏ (–ø–æ 2 —Å—Ç—Ä–æ–∫–∏ –Ω–∞ –∫–∞–∂–¥—É—é –Ω–æ–≤–æ—Å—Ç—å)
        for news in news_with_keywords:
            # –§–æ—Ä–º–∞—Ç–∏—Ä—É–µ–º –¥–∞—Ç—É
            formatted_date = ''
            if news.get('date'):
                try:
                    date_obj = datetime.strptime(news['date'], '%Y-%m-%d')
                    formatted_date = date_obj.strftime('%d.%m.%y')
                except:
                    formatted_date = news.get('date', '')
            
            # –ü–ï–†–í–ê–Ø –°–¢–†–û–ö–ê: –ª–æ–≥–æ + –¥–∞—Ç–∞ + –ø—Ä–æ–≥—Ä–∞–º–º–∞ + –∑–∞–≥–æ–ª–æ–≤–æ–∫
            row1_cells = table.add_row().cells
            
            # –£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º –≤–µ—Ä—Ç–∏–∫–∞–ª—å–Ω–æ–µ —Ü–µ–Ω—Ç—Ä–∏—Ä–æ–≤–∞–Ω–∏–µ –¥–ª—è –≤—Å–µ—Ö —è—á–µ–µ–∫ —Å—Ç—Ä–æ–∫–∏
            for cell in row1_cells:
                cell.vertical_alignment = WD_ALIGN_VERTICAL.CENTER
            
            # –ü—ã—Ç–∞–µ–º—Å—è –≤—Å—Ç–∞–≤–∏—Ç—å –ª–æ–≥–æ, –µ—Å–ª–∏ –Ω–µ –ø–æ–ª—É—á–∞–µ—Ç—Å—è - –≤—Å—Ç–∞–≤–ª—è–µ–º —Ç–µ–∫—Å—Ç
            try:
                if os.path.exists(logo_path):
                    # –î–æ–±–∞–≤–ª—è–µ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –ª–æ–≥–æ
                    paragraph = row1_cells[0].paragraphs[0]
                    paragraph.alignment = 1  # –¶–µ–Ω—Ç—Ä–∏—Ä—É–µ–º –ª–æ–≥–æ –≥–æ—Ä–∏–∑–æ–Ω—Ç–∞–ª—å–Ω–æ
                    run = paragraph.runs[0] if paragraph.runs else paragraph.add_run()
                    run.add_picture(logo_path, width=Inches(0.5))  # –†–∞–∑–º–µ—Ä –ª–æ–≥–æ
                else:
                    row1_cells[0].text = f"[–õ–û–ì–û]"
                    row1_cells[0].paragraphs[0].alignment = 1  # –¶–µ–Ω—Ç—Ä–∏—Ä—É–µ–º –≥–æ—Ä–∏–∑–æ–Ω—Ç–∞–ª—å–Ω–æ
            except Exception as e:
                print(f"‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å –≤—Å—Ç–∞–≤–∏—Ç—å –ª–æ–≥–æ: {e}")
                row1_cells[0].text = f"[–õ–û–ì–û]"
                row1_cells[0].paragraphs[0].alignment = 1  # –¶–µ–Ω—Ç—Ä–∏—Ä—É–µ–º –≥–æ—Ä–∏–∑–æ–Ω—Ç–∞–ª—å–Ω–æ
            
            row1_cells[1].text = formatted_date
            row1_cells[1].paragraphs[0].alignment = 1  # –¶–µ–Ω—Ç—Ä–∏—Ä—É–µ–º –¥–∞—Ç—É –≥–æ—Ä–∏–∑–æ–Ω—Ç–∞–ª—å–Ω–æ
            
            row1_cells[2].text = '¬´–ù–æ–≤–æ—Å—Ç–∏¬ª'
            row1_cells[2].paragraphs[0].alignment = 1  # –¶–µ–Ω—Ç—Ä–∏—Ä—É–µ–º –ø—Ä–æ–≥—Ä–∞–º–º—É –≥–æ—Ä–∏–∑–æ–Ω—Ç–∞–ª—å–Ω–æ
            
            row1_cells[3].text = news['title']
            # –ß–µ—Ç–≤–µ—Ä—Ç—ã–π —Å—Ç–æ–ª–±–µ—Ü –æ—Å—Ç–∞–µ—Ç—Å—è —Å –≤—ã—Ä–∞–≤–Ω–∏–≤–∞–Ω–∏–µ–º –ø–æ –ª–µ–≤–æ–º—É –∫—Ä–∞—é –≥–æ—Ä–∏–∑–æ–Ω—Ç–∞–ª—å–Ω–æ
            
            # –í–¢–û–†–ê–Ø –°–¢–†–û–ö–ê: –¥–æ–º–µ–Ω + –¥–∞—Ç–∞ + –ø—Ä–æ–≥—Ä–∞–º–º–∞ + —Å—Å—ã–ª–∫–∞
            row2_cells = table.add_row().cells
            
            # –£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º –≤–µ—Ä—Ç–∏–∫–∞–ª—å–Ω–æ–µ —Ü–µ–Ω—Ç—Ä–∏—Ä–æ–≤–∞–Ω–∏–µ –¥–ª—è –≤—Å–µ—Ö —è—á–µ–µ–∫ —Å—Ç—Ä–æ–∫–∏
            for cell in row2_cells:
                cell.vertical_alignment = WD_ALIGN_VERTICAL.CENTER
            
            row2_cells[0].text = site_domain
            row2_cells[0].paragraphs[0].alignment = 1  # –¶–µ–Ω—Ç—Ä–∏—Ä—É–µ–º –¥–æ–º–µ–Ω –≥–æ—Ä–∏–∑–æ–Ω—Ç–∞–ª—å–Ω–æ
            
            row2_cells[1].text = formatted_date
            row2_cells[1].paragraphs[0].alignment = 1  # –¶–µ–Ω—Ç—Ä–∏—Ä—É–µ–º –¥–∞—Ç—É –≥–æ—Ä–∏–∑–æ–Ω—Ç–∞–ª—å–Ω–æ
            
            row2_cells[2].text = '¬´–ù–æ–≤–æ—Å—Ç–∏¬ª'
            row2_cells[2].paragraphs[0].alignment = 1  # –¶–µ–Ω—Ç—Ä–∏—Ä—É–µ–º –ø—Ä–æ–≥—Ä–∞–º–º—É –≥–æ—Ä–∏–∑–æ–Ω—Ç–∞–ª—å–Ω–æ
            
            row2_cells[3].text = news.get('url', '')
            # –ß–µ—Ç–≤–µ—Ä—Ç—ã–π —Å—Ç–æ–ª–±–µ—Ü –æ—Å—Ç–∞–µ—Ç—Å—è —Å –≤—ã—Ä–∞–≤–Ω–∏–≤–∞–Ω–∏–µ–º –ø–æ –ª–µ–≤–æ–º—É –∫—Ä–∞—é –≥–æ—Ä–∏–∑–æ–Ω—Ç–∞–ª—å–Ω–æ
        
        print(f"üìã –°–æ–∑–¥–∞–Ω–∞ —Ç–∞–±–ª–∏—Ü–∞ —Å {len(news_with_keywords)} –Ω–æ–≤–æ—Å—Ç—è–º–∏ ({len(news_with_keywords) * 2} —Å—Ç—Ä–æ–∫)")
        return table

    def replace_variables_in_paragraph(self, paragraph, company_config, news_with_keywords, doc):
        """–ó–∞–º–µ–Ω—è–µ—Ç –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –≤ –ø–∞—Ä–∞–≥—Ä–∞—Ñ–µ, –≤–∫–ª—é—á–∞—è $report"""
        period_text = self.format_period_ru(self.start_date, self.end_date)
        n_value = str((len(news_with_keywords) if news_with_keywords else 0) * 10)
        replacements = {
            '$pre_company_full': company_config.get('pre_company_full', ''),
            '$company_short': company_config.get('company_short', ''),
            '$post_company_full': company_config.get('post_company_full', ''),
            '$date': period_text,
            '$legal_address': company_config.get('legal_address', ''),
            '$inn_kpp': company_config.get('inn_kpp', ''),
            '$email': company_config.get('email', ''),
            '$ceo_name': company_config.get('ceo_name', ''),
            '$n': n_value,
        }
        
        # –ü–æ–ª—É—á–∞–µ–º –≤–µ—Å—å —Ç–µ–∫—Å—Ç –ø–∞—Ä–∞–≥—Ä–∞—Ñ–∞
        full_text = paragraph.text
        original_text = full_text
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –µ—Å—Ç—å –ª–∏ –ø–µ—Ä–µ–º–µ–Ω–Ω–∞—è $report
        if '$report' in full_text:
            print(f"üîç –ù–∞–π–¥–µ–Ω–∞ –ø–µ—Ä–µ–º–µ–Ω–Ω–∞—è $report –≤ —Ç–µ–∫—Å—Ç–µ: {full_text}")
            
            # –ó–∞–º–µ–Ω—è–µ–º –æ—Å—Ç–∞–ª—å–Ω—ã–µ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –≤ —Ç–µ–∫—Å—Ç–µ
            text_parts = full_text.split('$report')
            text_before = text_parts[0] if len(text_parts) > 0 else ""
            text_after = text_parts[1] if len(text_parts) > 1 else ""
            
            # –ó–∞–º–µ–Ω—è–µ–º –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –≤ —á–∞—Å—Ç—è—Ö –¥–æ –∏ –ø–æ—Å–ª–µ $report
            for var, value in replacements.items():
                text_before = text_before.replace(var, value)
                text_after = text_after.replace(var, value)
            
            # –û—á–∏—â–∞–µ–º —Ç–µ–∫—É—â–∏–π –ø–∞—Ä–∞–≥—Ä–∞—Ñ –∏ –≤—Å—Ç–∞–≤–ª—è–µ–º —Ç–æ–ª—å–∫–æ —Ç–µ–∫—Å—Ç –¥–æ $report
            for run in paragraph.runs:
                run.text = ""
            
            if paragraph.runs:
                paragraph.runs[0].text = text_before
            else:
                paragraph.add_run(text_before)
            
            # –ü–æ–ª—É—á–∞–µ–º –ø–æ–∑–∏—Ü–∏—é —Ç–µ–∫—É—â–µ–≥–æ –ø–∞—Ä–∞–≥—Ä–∞—Ñ–∞ –≤ –¥–æ–∫—É–º–µ–Ω—Ç–µ
            paragraph_element = paragraph._element
            parent = paragraph_element.getparent()
            paragraph_index = list(parent).index(paragraph_element)
            
            # –°–æ–∑–¥–∞–µ–º —Ç–∞–±–ª–∏—Ü—É —Å –Ω–æ–≤–æ—Å—Ç—è–º–∏
            if news_with_keywords:
                site_domain = company_config.get('domain', 'radiovolna.fm')
                logo_path = company_config.get('logo_path', '../static/logos/logo_juka.png')
                
                # –°–æ–∑–¥–∞–µ–º —Ç–∞–±–ª–∏—Ü—É
                table = doc.add_table(rows=1, cols=4)
                table.style = 'Table Grid'
                
                # –ó–∞–≥–æ–ª–æ–≤–∫–∏ —Å—Ç–æ–ª–±—Ü–æ–≤
                header_cells = table.rows[0].cells
                header_cells[0].text = '–ù–∞–∏–º–µ–Ω–æ–≤–∞–Ω–∏–µ —Ä–∞–¥–∏–æ—Å—Ç–∞–Ω—Ü–∏–∏/—Å–∞–π—Ç–∞'
                header_cells[1].text = '–î–∞—Ç–∞ –∏ –≤—Ä–µ–º—è –≤—ã—Ö–æ–¥–∞ –≤ —ç—Ñ–∏—Ä'
                header_cells[2].text = '–ù–∞–∑–≤–∞–Ω–∏–µ –ø—Ä–æ–≥—Ä–∞–º–º—ã'
                header_cells[3].text = '–ù–∞–∑–≤–∞–Ω–∏–µ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–æ–Ω–Ω–æ–≥–æ –º–∞—Ç–µ—Ä–∏–∞–ª–∞/ —Å—Å—ã–ª–∫–∞ –Ω–∞ –ø—É–±–ª–∏–∫–∞—Ü–∏—é'
                
                # –î–µ–ª–∞–µ–º –∑–∞–≥–æ–ª–æ–≤–∫–∏ –∂–∏—Ä–Ω—ã–º–∏ –∏ —Ü–µ–Ω—Ç—Ä–∏—Ä—É–µ–º
                for i, cell in enumerate(header_cells):
                    cell.vertical_alignment = WD_ALIGN_VERTICAL.CENTER
                    for paragraph_cell in cell.paragraphs:
                        for run in paragraph_cell.runs:
                            run.font.bold = True
                        if i < 3:
                            paragraph_cell.alignment = 1
                
                # –î–æ–±–∞–≤–ª—è–µ–º —Å—Ç—Ä–æ–∫–∏ —Å –Ω–æ–≤–æ—Å—Ç—è–º–∏
                for news in news_with_keywords:
                    # –§–æ—Ä–º–∞—Ç–∏—Ä—É–µ–º –¥–∞—Ç—É
                    formatted_date = ''
                    if news.get('date'):
                        try:
                            date_obj = datetime.strptime(news['date'], '%Y-%m-%d')
                            formatted_date = date_obj.strftime('%d.%m.%y')
                        except:
                            formatted_date = news.get('date', '')
                    
                    # –ü–ï–†–í–ê–Ø –°–¢–†–û–ö–ê: –ª–æ–≥–æ + –¥–∞—Ç–∞ + –ø—Ä–æ–≥—Ä–∞–º–º–∞ + –∑–∞–≥–æ–ª–æ–≤–æ–∫
                    row1_cells = table.add_row().cells
                    for cell in row1_cells:
                        cell.vertical_alignment = WD_ALIGN_VERTICAL.CENTER
                    
                    # –õ–æ–≥–æ
                    try:
                        if os.path.exists(logo_path):
                            paragraph_logo = row1_cells[0].paragraphs[0]
                            paragraph_logo.alignment = 1
                            run = paragraph_logo.runs[0] if paragraph_logo.runs else paragraph_logo.add_run()
                            run.add_picture(logo_path, width=Inches(0.5))
                        else:
                            row1_cells[0].text = "[–õ–û–ì–û]"
                            row1_cells[0].paragraphs[0].alignment = 1
                    except Exception as e:
                        row1_cells[0].text = "[–õ–û–ì–û]"
                        row1_cells[0].paragraphs[0].alignment = 1
                    
                    row1_cells[1].text = formatted_date
                    row1_cells[1].paragraphs[0].alignment = 1
                    row1_cells[2].text = '¬´–ù–æ–≤–æ—Å—Ç–∏¬ª'
                    row1_cells[2].paragraphs[0].alignment = 1
                    row1_cells[3].text = news['title']
                    
                    # –í–¢–û–†–ê–Ø –°–¢–†–û–ö–ê: –¥–æ–º–µ–Ω + –¥–∞—Ç–∞ + –ø—Ä–æ–≥—Ä–∞–º–º–∞ + —Å—Å—ã–ª–∫–∞
                    row2_cells = table.add_row().cells
                    for cell in row2_cells:
                        cell.vertical_alignment = WD_ALIGN_VERTICAL.CENTER
                    
                    row2_cells[0].text = site_domain
                    row2_cells[0].paragraphs[0].alignment = 1
                    row2_cells[1].text = formatted_date
                    row2_cells[1].paragraphs[0].alignment = 1
                    row2_cells[2].text = '¬´–ù–æ–≤–æ—Å—Ç–∏¬ª'
                    row2_cells[2].paragraphs[0].alignment = 1
                    row2_cells[3].text = news.get('url', '')
                
                # –í—Å—Ç–∞–≤–ª—è–µ–º —Ç–∞–±–ª–∏—Ü—É –°–†–ê–ó–£ –ü–û–°–õ–ï —Ç–µ–∫—É—â–µ–≥–æ –ø–∞—Ä–∞–≥—Ä–∞—Ñ–∞
                table_element = table._element
                parent.insert(paragraph_index + 1, table_element)
                
                print(f"üìã –¢–∞–±–ª–∏—Ü–∞ –≤—Å—Ç–∞–≤–ª–µ–Ω–∞ –Ω–∞ –º–µ—Å—Ç–æ $report —Å {len(news_with_keywords)} –Ω–æ–≤–æ—Å—Ç—è–º–∏")
            
            # –ï—Å–ª–∏ –µ—Å—Ç—å —Ç–µ–∫—Å—Ç –ø–æ—Å–ª–µ $report, –¥–æ–±–∞–≤–ª—è–µ–º –µ–≥–æ –≤ –Ω–æ–≤—ã–π –ø–∞—Ä–∞–≥—Ä–∞—Ñ
            if text_after.strip():
                new_paragraph = doc.add_paragraph(text_after)
                new_paragraph_element = new_paragraph._element
                parent.insert(paragraph_index + 2, new_paragraph_element)
            
            return True
        
        # –û–±—ã—á–Ω–∞—è –∑–∞–º–µ–Ω–∞ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö (–µ—Å–ª–∏ –Ω–µ—Ç $report)
        has_variables = any(var in full_text for var in replacements.keys())
        
        if has_variables:
            print(f"üîç –ù–∞–π–¥–µ–Ω —Ç–µ–∫—Å—Ç —Å –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–º–∏: {full_text}")
            
            new_text = full_text
            for var, value in replacements.items():
                if var in new_text:
                    new_text = new_text.replace(var, value)
                    print(f"üîÑ –ó–∞–º–µ–Ω–µ–Ω–æ: {var} ‚Üí {value}")
            
            if new_text != original_text:
                for run in paragraph.runs:
                    run.text = ""
                
                if paragraph.runs:
                    paragraph.runs[0].text = new_text
                else:
                    paragraph.add_run(new_text)
                
                print(f"‚úÖ –û–±–Ω–æ–≤–ª–µ–Ω –ø–∞—Ä–∞–≥—Ä–∞—Ñ: {new_text}")
        
        return False

    def replace_variables_in_cell(self, cell, company_config, news_with_keywords, doc):
        """–ó–∞–º–µ–Ω—è–µ—Ç –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –≤ —è—á–µ–π–∫–µ —Ç–∞–±–ª–∏—Ü—ã"""
        for paragraph in cell.paragraphs:
            self.replace_variables_in_paragraph(paragraph, company_config, news_with_keywords, doc)

    def process_template_document(self, news_with_keywords, company_name='–Æ–∂–∫–∞'):
        """–û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç template.docx: –∫–æ–ø–∏—Ä—É–µ—Ç —à–∞–±–ª–æ–Ω, –∑–∞–º–µ–Ω—è–µ—Ç –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –≤–∫–ª—é—á–∞—è $report"""
        try:
            # –ü–æ–ª—É—á–∞–µ–º –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é –∫–æ–º–ø–∞–Ω–∏–∏
            company_config = self.config.get('reports', {}).get('docs', {}).get(company_name, {})
            if not company_config:
                print(f"‚ùå –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è –¥–ª—è '{company_name}' –Ω–µ –Ω–∞–π–¥–µ–Ω–∞")
                return None
            
            print(f"üîß –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è '{company_name}':")
            for key, value in company_config.items():
                print(f"   {key}: {value}")
            
            # –ü—É—Ç–∏ –∫ .docx —Ñ–∞–π–ª–∞–º
            template_paths = [
                "static/template.docx",
                "../static/template.docx"
            ]
            
            template_path = None
            for path in template_paths:
                if os.path.exists(path):
                    template_path = path
                    break
            
            if not template_path:
                print("‚ùå –§–∞–π–ª template.docx –Ω–µ –Ω–∞–π–¥–µ–Ω")
                return None
            
            print(f"üìÑ –ò—Å–ø–æ–ª—å–∑—É–µ–º —à–∞–±–ª–æ–Ω: {template_path}")
            
            # –°–æ–∑–¥–∞–µ–º –ø–∞–ø–∫—É reports, –µ—Å–ª–∏ –µ—ë –Ω–µ—Ç
            os.makedirs(self.reports_path, exist_ok=True)
            
            # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º –∏–º—è –≤—ã—Ö–æ–¥–Ω–æ–≥–æ —Ñ–∞–π–ª–∞
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            output_filename = f"processed_document_{company_name}_{timestamp}.docx"
            output_path = os.path.join(self.reports_path, output_filename)
            
            # –ö–æ–ø–∏—Ä—É–µ–º .docx —Ñ–∞–π–ª —Ü–µ–ª–∏–∫–æ–º
            print("üìã –ö–æ–ø–∏—Ä—É–µ–º template.docx...")
            shutil.copy2(template_path, output_path)
            doc = Document(output_path)
            
            print("üîÑ –ò—â–µ–º –∏ –∑–∞–º–µ–Ω—è–µ–º –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ...")
            
            # –ó–∞–º–µ–Ω—è–µ–º –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –≤–æ –≤—Å–µ—Ö –ø–∞—Ä–∞–≥—Ä–∞—Ñ–∞—Ö
            # –í–∞–∂–Ω–æ: –ø—Ä–æ—Ö–æ–¥–∏–º –ø–æ –∫–æ–ø–∏–∏ —Å–ø–∏—Å–∫–∞, —Ç–∞–∫ –∫–∞–∫ –º—ã –º–æ–∂–µ–º –∏–∑–º–µ–Ω—è—Ç—å –¥–æ–∫—É–º–µ–Ω—Ç
            paragraphs = list(doc.paragraphs)
            for paragraph in paragraphs:
                if paragraph.text.strip():
                    self.replace_variables_in_paragraph(paragraph, company_config, news_with_keywords, doc)
            
            # –ó–∞–º–µ–Ω—è–µ–º –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –≤ —Ç–∞–±–ª–∏—Ü–∞—Ö
            for table_num, table in enumerate(doc.tables):
                print(f"ÔøΩÔøΩ –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º —Ç–∞–±–ª–∏—Ü—É {table_num + 1}")
                for row_num, row in enumerate(table.rows):
                    for cell_num, cell in enumerate(row.cells):
                        if cell.text.strip():
                            self.replace_variables_in_cell(cell, company_config, news_with_keywords, doc)
            
            print("‚úÖ –û–±—Ä–∞–±–æ—Ç–∫–∞ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö –∑–∞–≤–µ—Ä—à–µ–Ω–∞")
            
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º –æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã–π –¥–æ–∫—É–º–µ–Ω—Ç
            doc.save(output_path)
            print(f"ÔøΩÔøΩ –î–æ–∫—É–º–µ–Ω—Ç —Å–æ—Ö—Ä–∞–Ω–µ–Ω: {output_path}")
            
            return output_path
            
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –¥–æ–∫—É–º–µ–Ω—Ç–∞: {e}")
            import traceback
            traceback.print_exc()
            return None

    def print_results(self, news_items):
        """–í—ã–≤–æ–¥–∏—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –ø–∞—Ä—Å–∏–Ω–≥–∞"""
        for i, item in enumerate(news_items, 1):
            print(f"{i}. {item['title']}")
            if item.get('page_number'):
                print(f"   –°—Ç—Ä–∞–Ω–∏—Ü–∞: {item['page_number']}")
            if item['author']:
                print(f"   –ê–≤—Ç–æ—Ä: {item['author']}")
            if item['date']:
                print(f"   –î–∞—Ç–∞: {item['date']}")
            print(f"   URL: {item['url']}")
            print()

    def format_period_ru(self, start_iso: str, end_iso: str) -> str:
        """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –ø–µ—Ä–∏–æ–¥ –≤ —Ñ–æ—Ä–º–∞—Ç–µ: 15 –ø–æ 21 –∞–≤–≥—É—Å—Ç–∞ 2025 (—Å —É—á–µ—Ç–æ–º –º–µ—Å—è—Ü–µ–≤ –∏ –≥–æ–¥–∞).
        –û–∂–∏–¥–∞–µ—Ç ISO —Å—Ç—Ä–æ–∫–∏ YYYY-MM-DD."""
        try:
            start_dt = datetime.strptime(start_iso, "%Y-%m-%d")
            end_dt = datetime.strptime(end_iso, "%Y-%m-%d")
        except Exception:
            # –í —Å–ª—É—á–∞–µ –æ—à–∏–±–∫–∏ –ø—Ä–æ—Å—Ç–æ –≤–µ—Ä–Ω–µ–º –∏—Å—Ö–æ–¥–Ω—ã–µ —Å—Ç—Ä–æ–∫–∏
            return f"{start_iso} ‚Äî {end_iso}"
        months_gen = [
            "—è–Ω–≤–∞—Ä—è", "—Ñ–µ–≤—Ä–∞–ª—è", "–º–∞—Ä—Ç–∞", "–∞–ø—Ä–µ–ª—è", "–º–∞—è", "–∏—é–Ω—è",
            "–∏—é–ª—è", "–∞–≤–≥—É—Å—Ç–∞", "—Å–µ–Ω—Ç—è–±—Ä—è", "–æ–∫—Ç—è–±—Ä—è", "–Ω–æ—è–±—Ä—è", "–¥–µ–∫–∞–±—Ä—è"
        ]
        if start_dt.year == end_dt.year:
            if start_dt.month == end_dt.month:
                # 15 –ø–æ 21 –∞–≤–≥—É—Å—Ç–∞ 2025
                month_name = months_gen[end_dt.month - 1]
                return f"{start_dt.day} –ø–æ {end_dt.day} {month_name} {end_dt.year}"
            else:
                # 25 –∏—é–ª—è –ø–æ 03 –∞–≤–≥—É—Å—Ç–∞ 2025
                start_month = months_gen[start_dt.month - 1]
                end_month = months_gen[end_dt.month - 1]
                return f"{start_dt.day} {start_month} –ø–æ {end_dt.day} {end_month} {end_dt.year}"
        else:
            # 28 –¥–µ–∫–∞–±—Ä—è 2024 –ø–æ 03 —è–Ω–≤–∞—Ä—è 2025
            start_month = months_gen[start_dt.month - 1]
            end_month = months_gen[end_dt.month - 1]
            return f"{start_dt.day} {start_month} {start_dt.year} –ø–æ {end_dt.day} {end_month} {end_dt.year}"


def main():
    """–û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è"""
    parser = RadioVolnaParser()
    
    # –ë–∞–∑–æ–≤—ã–π URL
    base_url = "https://radiovolna.fm/"
    
    print("–ó–∞–ø—É—Å–∫ –ø–∞—Ä—Å–∏–Ω–≥–∞ —Å–µ–∫—Ü–∏–∏ '–ù–æ–≤—ã–µ –º–∞—Ç–µ—Ä–∏–∞–ª—ã' —Å –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–π –æ—Å—Ç–∞–Ω–æ–≤–∫–æ–π –ø–æ –¥–∞—Ç–∞–º...")
    print(f"–ë–∞–∑–æ–≤—ã–π URL: {base_url}")
    print(f"–î–∏–∞–ø–∞–∑–æ–Ω –¥–∞—Ç: {parser.start_date} ‚Äî {parser.end_date}")
    print("=" * 60)
    
    all_news = []
    seen_titles = set()  # –î–ª—è –æ—Ç—Å–ª–µ–∂–∏–≤–∞–Ω–∏—è —É–∂–µ –Ω–∞–π–¥–µ–Ω–Ω—ã—Ö –∑–∞–≥–æ–ª–æ–≤–∫–æ–≤
    page_num = 1  # –ù–∞—á–∏–Ω–∞–µ–º —Å –ø–µ—Ä–≤–æ–π —Å—Ç—Ä–∞–Ω–∏—Ü—ã
    
    # –¶–∏–∫–ª —Å –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–π –æ—Å—Ç–∞–Ω–æ–≤–∫–æ–π –ø–æ –¥–∞—Ç–∞–º
    while True:
        target_url = f"{base_url}?PAGEN_4={page_num}"
        
        print(f"\nüìÑ –°–¢–†–ê–ù–ò–¶–ê {page_num}")
        print(f"URL: {target_url}")
        print("-" * 40)
        
        # –ü–æ–ª—É—á–∞–µ–º —Å–æ–¥–µ—Ä–∂–∏–º–æ–µ —Å—Ç—Ä–∞–Ω–∏—Ü—ã
        page_content = parser.get_page_content(target_url)
        if not page_content:
            print(f"‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å —Å—Ç—Ä–∞–Ω–∏—Ü—É {page_num}")
            page_num += 1
            continue
        
        # –ü–∞—Ä—Å–∏–º —Å–µ–∫—Ü–∏—é "–ù–æ–≤—ã–µ –º–∞—Ç–µ—Ä–∏–∞–ª—ã"
        news_data = parser.parse_new_materials_section(page_content)
        
        if news_data:
            # –§–∏–ª—å—Ç—Ä—É–µ–º –¥—É–±–ª–∏ –ø–æ –∑–∞–≥–æ–ª–æ–≤–∫—É –∏ –ø—Ä–æ–≤–µ—Ä—è–µ–º –¥–∞—Ç—ã
            new_items = []
            items_before_start = []  # –ù–æ–≤–æ—Å—Ç–∏ —Å—Ç–∞—Ä—à–µ start_date
            
            for item in news_data:
                if item['title'] not in seen_titles:
                    item['page_number'] = page_num
                    
                    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –¥–∞—Ç—É
                    if item['date'] and item['date'] < parser.start_date:
                        items_before_start.append(item)
                    else:
                        new_items.append(item)
                        seen_titles.add(item['title'])
            
            print(f"‚úÖ –ù–∞–π–¥–µ–Ω–æ {len(news_data)} –Ω–æ–≤–æ—Å—Ç–µ–π –Ω–∞ —Å—Ç—Ä–∞–Ω–∏—Ü–µ {page_num}")
            if len(new_items) != len(news_data):
                filtered_count = len(news_data) - len(new_items)
                print(f"   üîÑ –ò—Å–∫–ª—é—á–µ–Ω–æ {filtered_count} (–¥—É–±–ª–∏ + –≤–Ω–µ –¥–∏–∞–ø–∞–∑–æ–Ω–∞)")
            print(f"   ‚ûï –î–æ–±–∞–≤–ª–µ–Ω–æ {len(new_items)} —É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö –Ω–æ–≤–æ—Å—Ç–µ–π –≤ –¥–∏–∞–ø–∞–∑–æ–Ω–µ")
            
            # –î–æ–±–∞–≤–ª—è–µ–º –Ω–æ–≤–æ—Å—Ç–∏ –≤ –¥–∏–∞–ø–∞–∑–æ–Ω–µ
            all_news.extend(new_items)
            
            # –í—ã–≤–æ–¥–∏–º —Ç–æ–ª—å–∫–æ —É–Ω–∏–∫–∞–ª—å–Ω—ã–µ –∑–∞–≥–æ–ª–æ–≤–∫–∏ —Å —ç—Ç–æ–π —Å—Ç—Ä–∞–Ω–∏—Ü—ã
            if new_items:
                print("\n–ù–æ–≤—ã–µ –∑–∞–≥–æ–ª–æ–≤–∫–∏ –≤ –¥–∏–∞–ø–∞–∑–æ–Ω–µ:")
                for i, item in enumerate(new_items, 1):
                    if item.get('has_search_keywords', False):
                        keywords_str = ', '.join(item.get('found_keywords', []))
                        print(f"  {i}. {item['title']} ({item['date']}) üîç [{keywords_str}]")
                    else:
                        print(f"  {i}. {item['title']} ({item['date']})")
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –µ—Å—Ç—å –ª–∏ –Ω–æ–≤–æ—Å—Ç–∏ —Å—Ç–∞—Ä—à–µ start_date
            if items_before_start:
                print(f"üèÅ –ù–∞–π–¥–µ–Ω—ã –Ω–æ–≤–æ—Å—Ç–∏ —Å—Ç–∞—Ä—à–µ {parser.start_date}, –∑–∞–≤–µ—Ä—à–∞–µ–º –ø–∞—Ä—Å–∏–Ω–≥")
                break
                
            # –ï—Å–ª–∏ –Ω–∞ —Å—Ç—Ä–∞–Ω–∏—Ü–µ –Ω–µ—Ç –Ω–æ–≤–æ—Å—Ç–µ–π –≤ –¥–∏–∞–ø–∞–∑–æ–Ω–µ, –Ω–æ –µ—Å—Ç—å –Ω–æ–≤–æ—Å—Ç–∏ - –ø—Ä–æ–¥–æ–ª–∂–∞–µ–º
            if not new_items and news_data:
                print("   ‚è≠Ô∏è –í—Å–µ –Ω–æ–≤–æ—Å—Ç–∏ –Ω–∞ —Å—Ç—Ä–∞–Ω–∏—Ü–µ –≤–Ω–µ –¥–∏–∞–ø–∞–∑–æ–Ω–∞, –ø—Ä–æ–≤–µ—Ä—è–µ–º —Å–ª–µ–¥—É—é—â—É—é")
        else:
            print(f"‚ùå –ù–æ–≤–æ—Å—Ç–∏ –Ω–µ –Ω–∞–π–¥–µ–Ω—ã –Ω–∞ —Å—Ç—Ä–∞–Ω–∏—Ü–µ {page_num}")
            # –ï—Å–ª–∏ –Ω–µ—Å–∫–æ–ª—å–∫–æ —Å—Ç—Ä–∞–Ω–∏—Ü –ø–æ–¥—Ä—è–¥ –ø—É—Å—Ç—ã–µ - –æ—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º—Å—è
            if page_num > 25:  # –ü–æ—Å–ª–µ 25 —Å—Ç—Ä–∞–Ω–∏—Ü—ã –æ—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º—Å—è –µ—Å–ª–∏ –ø—É—Å—Ç–æ
                print("üèÅ –°–ª–∏—à–∫–æ–º –º–Ω–æ–≥–æ –ø—É—Å—Ç—ã—Ö —Å—Ç—Ä–∞–Ω–∏—Ü, –∑–∞–≤–µ—Ä—à–∞–µ–º –ø–∞—Ä—Å–∏–Ω–≥")
                break
        
        # –ò–Ω–∫—Ä–µ–º–µ–Ω—Ç–∏—Ä—É–µ–º –Ω–æ–º–µ—Ä —Å—Ç—Ä–∞–Ω–∏—Ü—ã
        page_num += 1
        
        # –ü–∞—É–∑–∞ –º–µ–∂–¥—É –∑–∞–ø—Ä–æ—Å–∞–º–∏
        time.sleep(1)
        
        # –ó–∞—â–∏—Ç–∞ –æ—Ç –±–µ—Å–∫–æ–Ω–µ—á–Ω–æ–≥–æ —Ü–∏–∫–ª–∞
        if page_num > 100:
            print("‚ö†Ô∏è –î–æ—Å—Ç–∏–≥–Ω—É—Ç –ª–∏–º–∏—Ç —Å—Ç—Ä–∞–Ω–∏—Ü (100), –∑–∞–≤–µ—Ä—à–∞–µ–º –ø–∞—Ä—Å–∏–Ω–≥")
            break
    
    # –û–±—â–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
    print(f"\n{'='*60}")
    print(f"–û–ë–©–ò–ï –†–ï–ó–£–õ–¨–¢–ê–¢–´")
    print(f"{'='*60}")
    
    if all_news:
        print(f"–í—Å–µ–≥–æ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–æ —Å—Ç—Ä–∞–Ω–∏—Ü: {page_num - 1}")
        print(f"–í—Å–µ–≥–æ –Ω–∞–π–¥–µ–Ω–æ –Ω–æ–≤–æ—Å—Ç–µ–π –≤ –¥–∏–∞–ø–∞–∑–æ–Ω–µ: {len(all_news)}")
        
        # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –¥–∏–∞–ø–∞–∑–æ–Ω –¥–∞—Ç –≤ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞—Ö
        dates = [item['date'] for item in all_news if item['date']]
        if dates:
            min_date = min(dates)
            max_date = max(dates)
            print(f"–î–∏–∞–ø–∞–∑–æ–Ω –¥–∞—Ç –≤ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞—Ö: {min_date} ‚Äî {max_date}")
        
        # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ –∫–ª—é—á–µ–≤—ã–º —Å–ª–æ–≤–∞–º
        news_with_keywords = [item for item in all_news if item.get('has_search_keywords', False)]
        print(f"–ù–æ–≤–æ—Å—Ç–µ–π —Å –∫–ª—é—á–µ–≤—ã–º–∏ —Å–ª–æ–≤–∞–º–∏: {len(news_with_keywords)} –∏–∑ {len(all_news)}")
        
        if news_with_keywords:
            # –ü–æ–¥—Å—á–∏—Ç—ã–≤–∞–µ–º —á–∞—Å—Ç–æ—Ç—É –∫–∞–∂–¥–æ–≥–æ –∫–ª—é—á–µ–≤–æ–≥–æ —Å–ª–æ–≤–∞
            keyword_count = {}
            for item in news_with_keywords:
                for keyword in item.get('found_keywords', []):
                    keyword_count[keyword] = keyword_count.get(keyword, 0) + 1
            
            print("–°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –∫–ª—é—á–µ–≤—ã—Ö —Å–ª–æ–≤:")
            for keyword, count in sorted(keyword_count.items(), key=lambda x: x[1], reverse=True):
                print(f"  '{keyword}': {count} —É–ø–æ–º–∏–Ω–∞–Ω–∏–π")
        
        # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º template.docx
        print(f"\n{'='*60}")
        print("–û–ë–†–ê–ë–û–¢–ö–ê –î–û–ö–£–ú–ï–ù–¢–ê")
        print(f"{'='*60}")
        
        doc_file = parser.process_template_document(news_with_keywords)
        
        if doc_file:
            print(f"‚úÖ –î–æ–∫—É–º–µ–Ω—Ç —É—Å–ø–µ—à–Ω–æ —Å–æ–∑–¥–∞–Ω: {doc_file}")
        else:
            print("‚ùå –û—à–∏–±–∫–∞ —Å–æ–∑–¥–∞–Ω–∏—è –¥–æ–∫—É–º–µ–Ω—Ç–∞")
        
    else:
        print("‚ùå –ù–æ–≤–æ—Å—Ç–∏ –Ω–µ –Ω–∞–π–¥–µ–Ω—ã –Ω–∏ –Ω–∞ –æ–¥–Ω–æ–π —Å—Ç—Ä–∞–Ω–∏—Ü–µ")


if __name__ == "__main__":
    main()
